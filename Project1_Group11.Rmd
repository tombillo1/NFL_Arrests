---
title: "Impact of Research on Univerisity Rankings"
author: "Thomas Billington, Steven Bottone, Nart Hakij, and Joe Manley"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction:
* Many schools either brand themselves as teaching, professional, or research focused universities.  
* By measuring the trends of institutions across the globe we can determine if their ability to conduct meaningful research correlate to its statute.  
* Goal: Does a university’s research efforts have an effect on its global ranking?  
* Response variable: Global ranking  
* Explanatory variable: Research score (out of 100)  
* Observations: 1695 universities 

\newpage

## Analysis: 
To better understand the relationship, a thorough statistical analysis was conducted.   

### Plot:
```{r chunk1, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
library(ggplot2)
data = read.csv("rankings.csv")
data = na.omit(data)
data$University.Rank <- as.numeric(data$University.Rank)
data$Research.Score <- as.numeric(data$Research.Score)

model <- lm(University.Rank ~ Research.Score, data = data)

# https://www.kaggle.com/datasets/alitaqi000/world-university-rankings-2023
plot = ggplot(data, aes(x = Research.Score, y = University.Rank)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", se = FALSE, color = "red") + ylim(0, NA) +
  labs(y = "University Rank", x = "Research Score") +
  ggtitle("University Rank vs Research Score")

plot


correlation = cor(data$University.Rank, data$Research.Score)
# correlation
```
From the graph there appears to be a strong negative linear relationship between research score and university ranking, however this will be validated in later tests. We see that as research score increases, rank decreases(goes towards better rank).  
  
\newpage
More information can be observed from better understanding the linear model:

### Model:  
```{r chunk2, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
coefficients <- coef(model)
intercept <- coefficients[1]
slope <- coefficients[2]

summary(model)
```
From this summary output we can note a few key details about the model.

* Ŷ = 1346.679 + (-21.23218)*X
* Ŷ is university ranking
* X is research score of university  

### Statistical Tests and Inference:  
  
Hypothesis Testing:  

* H0: There is no association between university ranking and research score  
* H1: There is an association between university ranking and research score    
  
The p-value was 2.2e^-16 which is much lower than the significance level of 0.05. Therefore, we can reject the null hypothesis, indicating that there is a strong statistical evidence that when university ranking decreases or gets closer to rank 1, research score increases.  
  
Correlation:    

* The R^2 value indicates that 54.2% of the variation in university rank can be explained by the research score.  
* The estimated residual standard error is s = 331.8 on 1695 degrees of freedom. This indicates that there is some variability in the models predictions.    
* Correlation coefficient between University.Rank and Research.Score: -0.736. This indicates a strong negative correlation, as one variable increases the other decreases.   
  
Confidence Intervals:
```{r chunk3, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
confidence_interval <- confint(model, level = 0.95)
confidence_interval
```
We are 95% confident that as the research score increases by 1%, the overall university rank decreases by 22.2 to 20.3 ranks.  
  
Graphical representation of data with intervals:  
```{r chunk4, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
plot2 = ggplot(data, aes(x = Research.Score, y = University.Rank)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", se = TRUE, color = "blue") + ylim(0, NA) +
  labs(y = "University Rank", x = "Research Score") +
  ggtitle("University Rank vs Research Score")
plot2
```
\newpage
  
### Prediction:
  
```{r chunk5, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}

```
### Transformation and Comparison:

Due to the shape of the data, a logarithmic transformation was applied.  
Graph of transformed data:  
```{r chunk6, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
ln_y = log(data$University.Rank)

plot2 = ggplot(data, aes(x = Research.Score, y = ln_y)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", se = TRUE, color = "blue") + ylim(0, NA) +
  labs(y = "University Rank", x = "Research Score") +
  ggtitle("University Rank vs Research Score")
plot2

```
  
Model information:  
```{r chunk7, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
model2 = lm(ln_y~Research.Score, data=data)
summary(model2)
```
From the transformation we can see that the R^2 value of the model is 0.8221. In comparison to the value from the original model (0.542) we can see that the there is a much stronger relationship between the variables when transformed. 

Correlation coefficient between log. transformed rank and research score:
```{r chunk8, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
cor(log(data$University.Rank), data$Research.Score)
```
  
From this score we see that the data also has a much stronger negative linear correlation with a score of -0.9067089 compared to the -0.736 value for the non-transformed rank.  
  
From these observations, we can choose the logarithmic transformed model as the better model. 

## Assumptions:

Follow the choosing of the logarithmic transformation model we now have to check the assumptions.  

Fitted values plot:  
```{r chunk9, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
plot(model2$residuals ~ model2$fitted.values, pch = 20)
```
\newpage  
QQplot of residuals:  
```{r chunk10, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
library(car)
qqPlot(model2$residuals, pch = 20)
```
\newpage  
Residuals vs Research Score:  
```{r chunk11, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
plot(model2$residuals~data$Research.Score, pch = 20)
abline(h=0, lty=3)
```
\newpage  
Histogram:  
```{r chunk12, echo=FALSE, warning=FALSE, comment=NA, message = FALSE}
hist(model2$residuals)
```
Assumption information:

Our data prior to transformation failed to meet most of our assumptions.  The relationship between research score and rank was nonlinear and appeared to follow a logarithmic trend.  Our assumption of constant variance also failed since our residuals and fitted values had a negative relationship.  The data was also not normally distributed, as most of the points in our QQ plot of residuals were not in the ideal range.  We were however able to assume that our data was independent.
After the transformation, our data followed a much stronger linear trend than before with a linear correlation score of -0.907, compared to -0.736 prior to transformation.   However, our test for constant variance failed again, but it was much closer than before.  The data is much closer to a normal distribution, but it still failed to satisfy our assumption.  We can still assume that the data was independent.

\newpage  

## Conclusions:

We were able to find a strong correlation between research score and the overall rank of a university. This being said, the relationship between them was not a simple linear regression. After a logarithmic transformation, the data fits into a linear regression much better (although still imperfectly). The information can be used to estimate a university’s overall rank given how good its research program is. A possible extension of this could be for people who want to improve their university’s standings, it is possible using this model to predict how good a university’s research program needs to be to reach a certain ranking. Another possible extension of this is for prospective students, if a student was interested in research specifically, they can predict how good a university’s research program will be based on its ranking.  


